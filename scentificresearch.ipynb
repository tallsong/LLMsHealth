{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca04959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bibtexparser # Used to read .bib files\n",
    "import re\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ieee_df = pd.read_csv(\"dataset/IEEE.csv\")\n",
    "ieee_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/acm.bib\", encoding=\"utf-8\") as bibtex_file:\n",
    "    bib_database = bibtexparser.load(bibtex_file)\n",
    "\n",
    "# Convert entries to a pandas DataFrame\n",
    "acm_df = pd.DataFrame(bib_database.entries)\n",
    "acm_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "springer_df = pd.read_parquet(\"dataset/springer.parquet\")\n",
    "springer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pubmed parquet\n",
    "pubmed_df = pd.read_parquet(\"dataset/pubmed.parquet\")\n",
    "\n",
    "pubmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciencedirect_df = pd.read_parquet(\"dataset/sciencedirect.parquet\")\n",
    "elsevier_df = sciencedirect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acefcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a list of tuples: (dataframe_name, title_series)\n",
    "df_sources = [\n",
    "    (\"ACM\", acm_df[\"title\"]),\n",
    "    (\"Elsevier\", elsevier_df[\"title\"]),\n",
    "    (\"IEEE\", ieee_df[\"Document Title\"]),\n",
    "    (\"PubMed\", pubmed_df[\"Title\"]),\n",
    "    (\"Springer\", springer_df[\"Item Title\"])\n",
    "]\n",
    "\n",
    "# 2. Create a combined DataFrame with source information\n",
    "combined_data = []\n",
    "for source_name, title_series in df_sources:\n",
    "    # Create a temporary DataFrame with title and source\n",
    "    temp_df = pd.DataFrame({\n",
    "        'title': title_series.str.lower(),  # Normalize to lowercase\n",
    "        'source': source_name\n",
    "    })\n",
    "    combined_data.append(temp_df)\n",
    "\n",
    "# Combine all into one DataFrame\n",
    "all_titles_df = pd.concat(combined_data, ignore_index=True)\n",
    "\n",
    "# 3. Remove rows with missing titles\n",
    "all_titles_df = all_titles_df.dropna(subset=['title'])\n",
    "\n",
    "# 4. Find titles that appear more than once\n",
    "title_counts = all_titles_df['title'].value_counts()\n",
    "duplicate_titles = title_counts[title_counts > 1].index.tolist()\n",
    "\n",
    "# 5. Filter to show only duplicates and group by title\n",
    "if not duplicate_titles:\n",
    "    print(\"No duplicate titles found across the DataFrames.\")\n",
    "else:\n",
    "    duplicates_df = all_titles_df[all_titles_df['title'].isin(duplicate_titles)]\n",
    "    \n",
    "    print(f\"Found {len(duplicate_titles)} duplicate titles across datasets\")\n",
    "    print(f\"Total duplicate entries: {len(duplicates_df)}\")\n",
    "    print(\"=\" * 80)\n",
    "    # Group by title and show which sources contain each duplicate\n",
    "    for title in sorted(duplicate_titles):\n",
    "        title_data = duplicates_df[duplicates_df['title'] == title]\n",
    "        sources = title_data['source'].tolist()\n",
    "        count = len(sources)\n",
    "        \n",
    "        print(f\"\\nTitle: {title}\")\n",
    "        print(f\"   Total occurrences: {count}\")\n",
    "        print(f\"   Found in: {', '.join(sources)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all dataframes to common schema: id, title, abstract, library, authors, doi, journal, date\n",
    "\n",
    "# ACM\n",
    "acm_df[\"library\"] = \"acm\"\n",
    "acm_df = acm_df.rename(columns={\n",
    "    \"ID\": \"id\", \"title\": \"title\", \"abstract\": \"abstract\", \"author\": \"authors\",\n",
    "    \"doi\": \"doi\", \"journal\": \"journal\", \"year\": \"date\"\n",
    "})\n",
    "for col in [\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]:\n",
    "    if col not in acm_df.columns:\n",
    "        acm_df[col] = pd.NA\n",
    "acm_df = acm_df[[\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]]\n",
    "\n",
    "# Elsevier\n",
    "elsevier_df[\"library\"] = \"elsevier\"\n",
    "elsevier_df = elsevier_df.rename(columns={\n",
    "    \"ID\": \"id\", \"title\": \"title\", \"abstract\": \"abstract\", \"author\": \"authors\",\n",
    "    \"doi\": \"doi\", \"journal\": \"journal\", \"year\": \"date\"\n",
    "})\n",
    "if \"date\" in elsevier_df.columns:\n",
    "    elsevier_df[\"date\"] = elsevier_df[\"date\"].astype(str)\n",
    "for col in [\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]:\n",
    "    if col not in elsevier_df.columns:\n",
    "        elsevier_df[col] = pd.NA\n",
    "elsevier_df = elsevier_df[[\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]]\n",
    "\n",
    "# IEEE\n",
    "ieee_df[\"library\"] = \"ieee\"\n",
    "ieee_df = ieee_df.rename(columns={\n",
    "    \"ISBNs\": \"id\", \"Document Title\": \"title\", \"Abstract\": \"abstract\", \"Authors\": \"authors\",\n",
    "    \"DOI\": \"doi\", \"Publication Title\": \"journal\", \"Online Date\": \"date\"\n",
    "})\n",
    "for col in [\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]:\n",
    "    if col not in ieee_df.columns:\n",
    "        ieee_df[col] = pd.NA\n",
    "ieee_df = ieee_df[[\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]]\n",
    "\n",
    "# PubMed\n",
    "pubmed_df[\"library\"] = \"pubmed\"\n",
    "pubmed_df = pubmed_df.rename(columns={\n",
    "    \"PMID\": \"id\", \"Title\": \"title\", \"abstract\": \"abstract\", \"Authors\": \"authors\",\n",
    "    \"DOI\": \"doi\", \"Journal/Book\": \"journal\", \"Create Date\": \"date\"\n",
    "})\n",
    "for col in [\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]:\n",
    "    if col not in pubmed_df.columns:\n",
    "        pubmed_df[col] = pd.NA\n",
    "pubmed_df = pubmed_df[[\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]]\n",
    "\n",
    "# Springer - USE ACTUAL COLUMN NAMES from the parquet file\n",
    "springer_df[\"library\"] = \"springer\"\n",
    "springer_df = springer_df.rename(columns={\n",
    "    \"Item Title\": \"title\", \"Abstract\": \"abstract\", \"Authors\": \"authors\",\n",
    "    \"Item DOI\": \"doi\", \"Publication Title\": \"journal\", \"Publication Year\": \"date\"\n",
    "})\n",
    "# Add ID if missing\n",
    "if \"id\" not in springer_df.columns:\n",
    "    springer_df[\"id\"] = range(len(springer_df))\n",
    "if \"date\" in springer_df.columns:\n",
    "    springer_df[\"date\"] = springer_df[\"date\"].astype(str)\n",
    "for col in [\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]:\n",
    "    if col not in springer_df.columns:\n",
    "        springer_df[col] = pd.NA\n",
    "springer_df = springer_df[[\"id\", \"title\", \"abstract\", \"library\", \"authors\", \"doi\", \"journal\", \"date\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ACM records after normalization: {len(acm_df)}\")\n",
    "print(f\"IEEE records after normalization: {len(ieee_df)}\")\n",
    "print(f\"PubMed records after normalization: {len(pubmed_df)}\")\n",
    "print(f\"Elsevier records after normalization: {len(elsevier_df)}\")\n",
    "print(f\"Springer records after normalization: {len(springer_df)}\")\n",
    "print(f\"\\nSpringer columns: {springer_df.columns.tolist()}\")\n",
    "print(f\"Springer library value counts:\\n{springer_df['library'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d754899",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([acm_df, elsevier_df, ieee_df, pubmed_df, springer_df], ignore_index=True)\n",
    "print(len(combined_df))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Library counts immediately after concat:\")\n",
    "print(combined_df['library'].value_counts())\n",
    "print(f\"Springer count: {(combined_df['library'] == 'springer').sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72389185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check library counts BEFORE duplicate removal\n",
    "print(\"Library counts BEFORE duplicate removal:\")\n",
    "print(combined_df['library'].value_counts())\n",
    "print(f\"\\nTotal records: {len(combined_df)}\\n\")\n",
    "\n",
    "# create a normalized comparison key\n",
    "combined_df['title_norm'] = combined_df['title'].str.lower().str.strip()\n",
    "\n",
    "# group and filter to only duplicated titles\n",
    "dupes = combined_df[combined_df.duplicated('title_norm', keep=False)]\n",
    "\n",
    "# now show which libraries the duplicates belong to\n",
    "result = dupes.groupby('title_norm')['library'].unique().reset_index()\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP DUPLICATES\n",
    "combined_df['title_norm'] = combined_df['title'].str.lower().str.strip()\n",
    "\n",
    "# find duplicated keys\n",
    "dupe_keys = combined_df['title_norm'][combined_df['title_norm'].duplicated(keep=False)]\n",
    "\n",
    "# remove every row with those keys\n",
    "combined_df = combined_df[~combined_df['title_norm'].isin(dupe_keys)]\n",
    "\n",
    "combined_df = combined_df.drop(columns='title_norm')\n",
    "# remove journal is medRxiv\n",
    "combined_df = combined_df[combined_df['journal'] != 'medRxiv']\n",
    "\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# caculate group count by library, and draw a bar chart\n",
    "library_counts = combined_df['library'].value_counts()\n",
    "print(library_counts)\n",
    "library_counts.plot(kind='bar', title='Number of Records by Library')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine all abstracts into one string\n",
    "all_abstracts = ' '.join(combined_df['abstract'].dropna().astype(str))\n",
    "\n",
    "# Create wordcloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_abstracts)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Wordcloud of Abstracts')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by journal and order by count descending\n",
    "top15journal = combined_df.groupby('journal').size().sort_values(ascending=False).head(15)\n",
    "# plot bar chart\n",
    "top15journal.plot(kind='bar', title='Top 15 Journals by Number of Publications')\n",
    "\n",
    "\n",
    "# TODO a bar chart showsinig publication by each quarter\n",
    "# TODO chang the color of  earhc plot\n",
    "# TODO build occurance martix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf00ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "custom_regex_dict = {\n",
    "    'chatgpt': re.compile(r'\\b(chat[\\s\\-\\.]*gpt)\\b|\\b(gpt)\\b', re.IGNORECASE),\n",
    "    'gpt-4': re.compile(r'\\b(gpt[\\s\\-\\.]*4(o|\\s*turbo)?)\\b', re.IGNORECASE),\n",
    "    'gpt-3.5': re.compile(r'\\b(gpt[\\s\\-\\.]*3[\\s\\-\\.]*5)\\b', re.IGNORECASE),\n",
    "    'gpt-5': re.compile(r'\\b(gpt[\\s\\-\\.]*5)\\b', re.IGNORECASE), \n",
    "    'gpt-3': re.compile(r'\\b(gpt[\\s\\-\\.]*3)\\b', re.IGNORECASE),\n",
    "    'gemini': re.compile(r'\\b(gemini)\\b', re.IGNORECASE),\n",
    "    'deepseek': re.compile(r'\\b(deepseek)\\b', re.IGNORECASE),\n",
    "    'llama': re.compile(r'\\b(llama)\\b', re.IGNORECASE),\n",
    "    'claude': re.compile(\n",
    "        r'\\b(claude)[\\s\\-\\.]*(\\(anthropic\\)|\\s*anthropic)?\\b|\\b(anthropic)\\b', \n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'mistral': re.compile(\n",
    "    # Matches: 'mistral', 'mistral (le chat)', 'mistral le-chat'\n",
    "    r'\\b(mistral)[\\s\\-\\.]*(\\(le[\\s\\-\\.]*chat\\)|\\s*le[\\s\\-\\.]*chat)?\\b'\n",
    "    # OR Matches: 'le chat', 'le-chat', 'lechat' (requires 'le' and 'chat' together)\n",
    "    r'|\\b(le[\\s\\-\\.]*chat)\\b', \n",
    "    re.IGNORECASE\n",
    "    ),\n",
    "    'medgemma': re.compile(r'\\b(med[\\s\\-\\.]*gemma)\\b', re.IGNORECASE),\n",
    "    'gemma': re.compile(r'\\b(gemma)\\b', re.IGNORECASE),\n",
    "    'med-palm': re.compile(r'\\b(med[\\s\\-\\.]*palm)\\b', re.IGNORECASE), \n",
    "    'bert': re.compile(r'\\b(bert)\\b', re.IGNORECASE),\n",
    "    'qwen': re.compile(r'\\b(qwen)\\b', re.IGNORECASE),\n",
    "    'falcon': re.compile(r'\\b(falcon)\\b', re.IGNORECASE),\n",
    "    'phi': re.compile(r'\\b(phi)\\b', re.IGNORECASE),\n",
    "    'pubmedbert': re.compile(r'\\b(pubmedbert)\\b', re.IGNORECASE),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_keywords = [\"performance\", \"method\", \"patient evaluated\", \"quality research\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7becad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_llms(text, regex_dict):\n",
    "    \"\"\"Finds all unique canonical LLMs that match a pattern in the text.\"\"\"\n",
    "    found_llms = []\n",
    "    for llm_name, pattern in regex_dict.items():\n",
    "        if pattern.search(text):\n",
    "            found_llms.append(llm_name)\n",
    "    return list(set(found_llms))\n",
    "\n",
    "def find_topics(text, keywords):\n",
    "    \"\"\"Finds all unique keywords that appear in the text.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    found_topics = []\n",
    "    for keyword in keywords:\n",
    "        # Simple substring search is sufficient since the topics are single words\n",
    "        if keyword in text_lower:\n",
    "            found_topics.append(keyword)\n",
    "    return list(set(found_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the functions to the DataFrame\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "df = combined_df.copy()\n",
    "df['Found_LLMs'] = df['abstract'].apply(\n",
    "    lambda x: find_llms(x, custom_regex_dict) if pd.notna(x) else []\n",
    ")\n",
    "\n",
    "# Find Topics\n",
    "df['Found_Topics'] = df['abstract'].apply(\n",
    "    lambda x: find_topics(x, topic_keywords) if pd.notna(x) else []\n",
    ")\n",
    "# Define Matrix Axes\n",
    "llm_labels = list(custom_regex_dict.keys())\n",
    "topic_labels = topic_keywords\n",
    "\n",
    "# Initialize the Occurrence Matrix\n",
    "occurrence_matrix = pd.DataFrame(\n",
    "    np.zeros((len(topic_labels), len(llm_labels)), dtype=int),\n",
    "    index=topic_labels,\n",
    "    columns=llm_labels\n",
    ")\n",
    "\n",
    "# Populate the occurrence matrix\n",
    "for _, row in df.iterrows():\n",
    "    llms_in_doc = row['Found_LLMs']\n",
    "    topics_in_doc = row['Found_Topics']\n",
    "    \n",
    "    # Iterate over every combination of LLM and Topic found in the document\n",
    "    for topic in topics_in_doc:\n",
    "        for llm in llms_in_doc:\n",
    "            # Increment the count where the topic and LLM co-occur\n",
    "            occurrence_matrix.loc[topic, llm] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(\n",
    "    occurrence_matrix,\n",
    "    annot=True,        # Show the count in each cell\n",
    "    cmap=\"Blues\", # Reversed color map for better contrast\n",
    "    linewidths=.5,     \n",
    "    linecolor='black',\n",
    "    fmt='d' # forces integer display\n",
    ")\n",
    "plt.title('Co-occurrence Matrix: LLMs vs. Application Topics', fontsize=16)\n",
    "plt.xlabel('Language Model', fontsize=14)\n",
    "plt.ylabel('Application Topic', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
